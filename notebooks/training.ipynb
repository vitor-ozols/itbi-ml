{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f35e46",
   "metadata": {},
   "source": [
    "\n",
    "### Modelo Hedônico IPTU — Treinamento Multifaixas com CatBoost\n",
    "\n",
    "Este notebook realiza o treinamento de um **modelo hedônico** para estimar o valor de transação (ITBI/IPTU),\n",
    "utilizando **CatBoostRegressor** com variáveis cadastrais do imóvel e **agregados mensais defasados (lag-1)**\n",
    "por **setor fiscal** e **grupo de uso** (TERRENO vs EDIFICADO).\n",
    "\n",
    "A abordagem é **multifaixas**: treina-se um modelo por combinação de:\n",
    "- `grupo_uso` ∈ {`TERRENO`, `EDIFICADO`}\n",
    "- `faixa` ∈ faixas de valor (<=500k, 500k–2mi, 2mi–10mi, >10mi)\n",
    "\n",
    "A variável-alvo é modelada em **log** (`log1p(valor / escala)`) para estabilizar variância e melhorar ajuste.\n",
    "\n",
    "%% [markdown]\n",
    "### 1) Imports\n",
    "\n",
    "- **glob / Path**: varredura recursiva dos Parquets na camada staging.\n",
    "- **pandas / numpy**: manipulação de dados e engenharia de atributos.\n",
    "- **catboost**: regressão com suporte nativo a variáveis categóricas.\n",
    "- **sklearn**: validação cruzada (KFold) e métricas (MAE e R²)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb73bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn catboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def6b6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from catboost import CatBoostRegressor, Pool\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036497",
   "metadata": {},
   "source": [
    "### 2) Configurações\n",
    "\n",
    "- `STAGING_PATH`: caminho para os Parquets já padronizados (camada staging).\n",
    "- `ARTEFATOS_PATH`: diretório para salvar modelos e metadados do treinamento.\n",
    "- `TARGET_SCALE`: escala aplicada antes do log para melhorar estabilidade numérica.\n",
    "\n",
    "#### Multifaixas\n",
    "As faixas são definidas por `FAIXAS_BINS` e `FAIXAS_LABELS`, utilizadas para:\n",
    "- segmentar o treinamento por nível de preço\n",
    "- permitir modelos especializados em regimes distintos (ex.: imóveis baratos vs caros)\n",
    "\n",
    "#### Variáveis categóricas\n",
    "`CAT_COLS` são passadas explicitamente ao CatBoost via `cat_features` (sem necessidade de one-hot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a7e67ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BRONZE_PATH = \"../data/bronze/itbi\"\n",
    "ARTEFATOS_PATH = \"../data/artefatos_modelo_multifaixas\"\n",
    "Path(ARTEFATOS_PATH).mkdir(exist_ok=True)\n",
    "\n",
    "TARGET_SCALE = 1000.0\n",
    "\n",
    "FAIXAS_BINS = [0, 500_000, 2_000_000, 10_000_000, np.inf]\n",
    "FAIXAS_LABELS = [\n",
    "    \"faixa1_<=500k\",\n",
    "    \"faixa2_500k_2mi\",\n",
    "    \"faixa3_2mi_10mi\",\n",
    "    \"faixa4_>10mi\"\n",
    "]\n",
    "\n",
    "CAT_COLS = [\n",
    "    \"setor_fiscal\",\n",
    "    \"descricao_uso_iptu\",\n",
    "    \"descricao_padrao_iptu\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77234859",
   "metadata": {},
   "source": [
    "### 3) Carregar Parquets (camada staging)\n",
    "\n",
    "- Varre recursivamente todos os arquivos `.parquet` em `STAGING_PATH`.\n",
    "- Concatena em um único DataFrame para treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de65dbb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Carregando parquets...\n",
      "Base carregada: 2600551 linhas\n"
     ]
    }
   ],
   "source": [
    "print(\">> Carregando parquets...\")\n",
    "files = glob.glob(f\"{BRONZE_PATH}/**/*.parquet\", recursive=True)\n",
    "df = pd.concat([pd.read_parquet(f) for f in files], ignore_index=True)\n",
    "print(\"Base carregada:\", len(df), \"linhas\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ce919",
   "metadata": {},
   "source": [
    "### 4) Filtros de qualidade e recorte do domínio\n",
    "\n",
    "Objetivo dos filtros:\n",
    "- restringir para transações comparáveis ao fenômeno modelado (compra e venda)\n",
    "- evitar registros com status não elegíveis\n",
    "- reduzir ruído extremo por outliers de valor\n",
    "\n",
    "Regras aplicadas:\n",
    "- `natureza_transacao = \"1.Compra e venda\"`\n",
    "- `sql_status em \"Ativo Territorial\"`\n",
    "- `valor_transacao_declarado entre 5000 a 50000000`\n",
    "- `proporcao_transmitida_percent igual a 100%`\n",
    "- `situacao_sql = \"Ativo Territorial\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"natureza_transacao\"] == \"1.Compra e venda\"]\n",
    "\n",
    "df = df[df[\"situacao_sql\"].isin([\"Ativo Predial\", \"Ativo Territorial\"])]\n",
    "\n",
    "df = df[df[\"valor_transacao_declarado\"].between(5000, 50_000_000)]\n",
    "\n",
    "df = df[df[\"proporcao_transmitida_percent\"] == 100]\n",
    "\n",
    "df = df[df[\"situacao_sql\"] == \"Ativo Predial\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62009b67",
   "metadata": {},
   "source": [
    "### 5) Feature engineering (atributos temporais e do imóvel)\n",
    "\n",
    "Atributos criados:\n",
    "- `year`, `month`, `yyyymm`: granularidade temporal e chave mensal\n",
    "- `imovel_idade`: idade aproximada do imóvel (ano transação - ano conclusão)\n",
    "- `grupo_uso`: binarização simples de uso: TERRENO vs EDIFICADO\n",
    "\n",
    "**Nota:** `imovel_idade` é truncada em 0 para evitar negativos (dados inconsistentes).\n",
    "Valores ausentes são tratados como 0 (estratégia conservadora)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ed1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"data_transacao\"] = pd.to_datetime(df[\"data_transacao\"], errors=\"coerce\")\n",
    "df[\"year\"] = df[\"data_transacao\"].dt.year\n",
    "df[\"month\"] = df[\"data_transacao\"].dt.month\n",
    "df[\"yyyymm\"] = df[\"year\"] * 100 + df[\"month\"]\n",
    "\n",
    "# Idade do imóvel (ano de transação - ano de conclusão)\n",
    "df[\"imovel_idade\"] = df[\"year\"] - df[\"ano_conclusao_construcao_iptu\"]\n",
    "df[\"imovel_idade\"] = df[\"imovel_idade\"].clip(lower=0).fillna(0)\n",
    "\n",
    "# Grupo de uso (heurística por descrição)\n",
    "df[\"grupo_uso\"] = np.where(\n",
    "    df[\"descricao_uso_iptu\"].str.contains(\"terren\", case=False, na=False),\n",
    "    \"TERRENO\",\n",
    "    \"EDIFICADO\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf10fea",
   "metadata": {},
   "source": [
    "### 6) Agregados mensais por setor fiscal (com defasagem)\n",
    "\n",
    "Nesta etapa criamos variáveis de contexto de mercado, por **mês**, **setor fiscal** e **grupo de uso**.\n",
    "\n",
    "Métricas mensais:\n",
    "- `median_total`: mediana do valor declarado no grupo\n",
    "- `median_sqm`: (atualmente igual à mediana do total; ver observação abaixo)\n",
    "- `count`: quantidade de transações no mês (proxy de liquidez)\n",
    "\n",
    "Em seguida, calculamos `lag-1` (mês anterior) para evitar vazamento temporal:\n",
    "- `median_total_lag1`, `median_sqm_lag1`, `count_lag1`\n",
    "\n",
    "**Observação importante:** `median_sqm` está calculado com a mesma expressão de `median_total`.\n",
    "Se a intenção for mediana do preço por m², o correto seria:\n",
    "`declared_transaction_value / built_area_sqm` (ou outra área relevante), com tratamento de divisão por zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62623d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "monthly = (\n",
    "    df.groupby([\"grupo_uso\", \"setor_fiscal\", \"yyyymm\"])\n",
    "      .agg(\n",
    "          median_total=(\"valor_transacao_declarado\", \"median\"),\n",
    "          median_sqm=(\"valor_transacao_declarado\", lambda x: np.median(x)),\n",
    "          count=(\"valor_transacao_declarado\", \"count\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "monthly[\"median_total_lag1\"] = (\n",
    "    monthly.sort_values(\"yyyymm\")\n",
    "           .groupby([\"grupo_uso\", \"setor_fiscal\"])[\"median_total\"]\n",
    "           .shift(1)\n",
    ")\n",
    "\n",
    "monthly[\"median_sqm_lag1\"] = (\n",
    "    monthly.sort_values(\"yyyymm\")\n",
    "           .groupby([\"grupo_uso\", \"setor_fiscal\"])[\"median_sqm\"]\n",
    "           .shift(1)\n",
    ")\n",
    "\n",
    "monthly[\"count_lag1\"] = (\n",
    "    monthly.sort_values(\"yyyymm\")\n",
    "           .groupby([\"grupo_uso\", \"setor_fiscal\"])[\"count\"]\n",
    "           .shift(1)\n",
    ")\n",
    "\n",
    "df = df.merge(\n",
    "    monthly[[\n",
    "        \"grupo_uso\",\n",
    "        \"setor_fiscal\",\n",
    "        \"yyyymm\",\n",
    "        \"median_total_lag1\",\n",
    "        \"median_sqm_lag1\",\n",
    "        \"count_lag1\"\n",
    "    ]],\n",
    "    on=[\"grupo_uso\", \"setor_fiscal\", \"yyyymm\"],\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff6c971",
   "metadata": {},
   "source": [
    "### 7) Definição do target (log-transform)\n",
    "\n",
    "Para reduzir assimetria (cauda longa) típica de valores imobiliários:\n",
    "- Definimos `target = log1p(valor / TARGET_SCALE)`\n",
    "\n",
    "No momento da avaliação (predição), desfazemos a transformação:\n",
    "- `valor_pred = expm1(pred) * TARGET_SCALE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d675a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"target\"] = np.log1p(df[\"valor_transacao_declarado\"] / TARGET_SCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd82225e",
   "metadata": {},
   "source": [
    "### 8) Criação das faixas de valor\n",
    "\n",
    "Segmenta cada registro em uma faixa baseada no `valor_transacao_declarado`.\n",
    "Isso permite treinar modelos especializados por regime de preços."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5162e4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"faixa\"] = pd.cut(\n",
    "    df[\"valor_transacao_declarado\"],\n",
    "    bins=FAIXAS_BINS,\n",
    "    labels=FAIXAS_LABELS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10b414e",
   "metadata": {},
   "source": [
    "### 9) Treinamento dos modelos (KFold 5x)\n",
    "\n",
    "Para cada `grupo_uso` e `faixa`:\n",
    "- Filtra o subconjunto (`sub`)\n",
    "- Se houver menos de 1000 registros, pula (amostra insuficiente)\n",
    "- Cria matriz `X` com:\n",
    "  - Categóricas: `CAT_COLS`\n",
    "  - Numéricas: área construída, área do terreno, testada, idade, yyyymm, lags do setor\n",
    "- Realiza validação cruzada KFold (5 folds)\n",
    "- Métricas por fold:\n",
    "  - **MAE** em R$ (no espaço original, após inversão do log)\n",
    "  - **R²** (coeficiente de determinação)\n",
    "\n",
    "Ao final, salva o último modelo treinado da iteração em:\n",
    "`artefatos_modelo_multifaixas/modelo_<grupo>_<faixa>.cbm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11aa0a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Treinando EDIFICADO - faixa1_<=500k (1219963 linhas)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['fiscal_sector', 'usage_description_iptu', 'construction_standard_description_iptu'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTreinando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrupo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfaixa\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sub)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m linhas)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m X = \u001b[43msub\u001b[49m\u001b[43m[\u001b[49m\u001b[43mCAT_COLS\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marea_construida_m2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marea_terreno_m2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtestada_m\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimovel_idade\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43myyyymm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedian_total_lag1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedian_sqm_lag1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcount_lag1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     24\u001b[39m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     26\u001b[39m y = sub[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     28\u001b[39m kf = KFold(n_splits=\u001b[32m5\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/itbi-ml/.venv/lib/python3.11/site-packages/pandas/core/frame.py:4384\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4382\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4383\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4384\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4386\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4387\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/itbi-ml/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6302\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6299\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6300\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6302\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6304\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6306\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/itbi-ml/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:6355\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6352\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6354\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6355\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['fiscal_sector', 'usage_description_iptu', 'construction_standard_description_iptu'] not in index\""
     ]
    }
   ],
   "source": [
    "modelos = {}\n",
    "\n",
    "for grupo in df[\"grupo_uso\"].unique():\n",
    "    modelos[grupo] = {}\n",
    "\n",
    "    for faixa in FAIXAS_LABELS:\n",
    "        sub = df[(df[\"grupo_uso\"] == grupo) & (df[\"faixa\"] == faixa)]\n",
    "\n",
    "        # Evita treinar com pouca amostra\n",
    "        if len(sub) < 1000:\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nTreinando {grupo} - {faixa} ({len(sub)} linhas)\")\n",
    "\n",
    "        X = sub[CAT_COLS + [\n",
    "            \"area_construida_m2\",\n",
    "            \"area_terreno_m2\",\n",
    "            \"testada_m\",\n",
    "            \"imovel_idade\",\n",
    "            \"yyyymm\",\n",
    "            \"median_total_lag1\",\n",
    "            \"median_sqm_lag1\",\n",
    "            \"count_lag1\"\n",
    "        ]]\n",
    "\n",
    "        y = sub[\"target\"]\n",
    "\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "        maes = []\n",
    "        r2s = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X), 1):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            model = CatBoostRegressor(\n",
    "                iterations=400,\n",
    "                depth=6,\n",
    "                learning_rate=0.05,\n",
    "                loss_function=\"RMSE\",\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            model.fit(\n",
    "                Pool(X_train, y_train, cat_features=CAT_COLS),\n",
    "                eval_set=Pool(X_val, y_val, cat_features=CAT_COLS),\n",
    "                verbose=False\n",
    "            )\n",
    "\n",
    "            # volta do log para R$\n",
    "            pred = np.expm1(model.predict(X_val)) * TARGET_SCALE\n",
    "            true = np.expm1(y_val) * TARGET_SCALE\n",
    "\n",
    "            mae = mean_absolute_error(true, pred)\n",
    "            r2 = r2_score(true, pred)\n",
    "\n",
    "            maes.append(mae)\n",
    "            r2s.append(r2)\n",
    "\n",
    "            print(f\"[Fold {fold}] MAE: R$ {mae:,.0f} | R²: {r2:.3f}\")\n",
    "\n",
    "        print(f\">> MÉDIA MAE: R$ {np.mean(maes):,.0f} | R²: {np.mean(r2s):.3f}\")\n",
    "\n",
    "        # guarda e salva o último modelo treinado\n",
    "        modelos[grupo][faixa] = model\n",
    "\n",
    "        model.save_model(\n",
    "            f\"{ARTEFATOS_PATH}/modelo_{grupo}_{faixa}.cbm\"\n",
    "        )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
